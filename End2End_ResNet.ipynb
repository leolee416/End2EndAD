{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-E2E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "按照摄像头类型将数据分为三类，`L`,`M`以及`R`。其中`L`与`R`的\"Steering\"标签会被人为添加一个偏移量，模拟汽车在偏离车道的情况下反向修正的操作，且这两种数据会全部用于训练模型（被分配到Training Set）。而`M`的数据会根据Training: Eval: Test = 6:3:1的比例来进行划分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Subset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from data_loader import SimulatorDataset  # Ensure data_loader.py is in the same directory\n",
    "from network_model import ModelCNN  # \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulator Data Loading Example\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set paths to the image and label directories\n",
    "image_dir = \"./data/Garching_dataset/straight/images\"  # Replace with your actual image directory\n",
    "label_dir = \"./data/Garching_dataset/straight/drivings\"  # Replace with your actual label directory\n",
    "\n",
    "# Define transformation for images (e.g., resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert PIL images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 按摄像头标签（L, M, R）分类数据\n",
    "def categorize_by_camera(dataset):\n",
    "    camera_data = {\"L\": [], \"M\": [], \"R\": []}\n",
    "    for idx in range(len(dataset)):\n",
    "        image_path = dataset.data_map[idx][\"image\"]\n",
    "        camera_type = dataset.data_map[idx][\"camera\"]\n",
    "        camera_data[camera_type].append(idx)\n",
    "    return camera_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12948 image files in ./data/Garching_dataset/straight/images.\n",
      "Found 4316 label files in ./data/Garching_dataset/straight/drivings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping Images to Labels: 100%|██████████| 12948/12948 [00:00<00:00, 110904.09file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully matched 12948 image-label pairs.\n",
      "Created data_map with 12948 entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_fields = [\"Steering\", \"Throttle\", \"Brake\"]  # 你想要的输出字段\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = SimulatorDataset(\n",
    "    image_dir=image_dir,\n",
    "    label_dir=label_dir,\n",
    "    transform= transform,\n",
    "    output_fields=output_fields # Specify desired output fields\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image at index 0: ./data/Garching_dataset/straight/images\\20241103_164545_000_L.png (Size: (640, 360))\n",
      "successfully transform the image\n",
      "Transformed image shape: torch.Size([3, 224, 224])\n",
      "Parsed labels from ./data/Garching_dataset/straight/drivings\\20241103_164545_000.csv: {'Throttle': 1.0, 'Brake': 0.0, 'Steering': 0.0, 'Wheel Angle': 0.0, 'Heading': -0.195734, 'Position': [-26481.492, 13759.909, 4.352], 'Speed': 1.805358, 'Acc': 0.208302, 'Direction': 1}\n",
      "Output labels for index 0: [0.20000000298023224, 1.0, 0.0]\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 检验，取出第一个样本\n",
    "image, label = dataset[0]\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 12948\n",
      "4316\n",
      "4316\n",
      "4316\n"
     ]
    }
   ],
   "source": [
    "# 将数据分类为 L, M, R\n",
    "camera_data = categorize_by_camera(dataset)\n",
    "data_L = camera_data[\"L\"]\n",
    "data_M = camera_data[\"M\"]\n",
    "data_R = camera_data[\"R\"]\n",
    "print(len(data_L))\n",
    "print(len(data_M))\n",
    "print(len(data_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大数据集分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 11221 samples\n",
      "Eval: 1295 samples\n",
      "Test: 432 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 对 M 数据划分为 train, eval, test\n",
    "train_M, temp_M = train_test_split(data_M, test_size=0.4, random_state=42)\n",
    "eval_M, test_M = train_test_split(temp_M, test_size=0.25, random_state=42)  # 30% eval, 10% test\n",
    "\n",
    "# train 集合包括 L、R 和部分 M\n",
    "train_indices = data_L + data_R + train_M\n",
    "\n",
    "# eval 和 test 集合仅包括 M\n",
    "eval_indices = eval_M\n",
    "test_indices = test_M\n",
    "\n",
    "# 打印划分结果\n",
    "print(f\"Train: {len(train_indices)} samples\")\n",
    "print(f\"Eval: {len(eval_indices)} samples\")\n",
    "print(f\"Test: {len(test_indices)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小数据集分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4316\n",
      "4316\n",
      "4316\n"
     ]
    }
   ],
   "source": [
    "print(len(data_L))\n",
    "print(len(data_M))\n",
    "print(len(data_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 从每个摄像头类别中抽取 50% 的数据\n",
    "random.seed(42)  # 固定随机种子，确保可重复性\n",
    "small_data_L = random.sample(data_L, len(data_L) // 3)\n",
    "small_data_M = random.sample(data_M, len(data_M) // 3)\n",
    "small_data_R = random.sample(data_R, len(data_R) // 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small Train: 3738 samples\n",
      "Small Eval: 432 samples\n",
      "Small Test: 144 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 对小数据集的 M 图像进行 6:3:1 分割\n",
    "train_M, temp_M = train_test_split(small_data_M, test_size=0.4, random_state=42)\n",
    "eval_M, test_M = train_test_split(temp_M, test_size=0.25, random_state=42)  # 30% eval, 10% test\n",
    "\n",
    "\n",
    "# 小数据集 train 集合包括 L、R 和部分 M\n",
    "small_train_indices = small_data_L + small_data_R + train_M\n",
    "\n",
    "# 小数据集 eval 和 test 集合仅包括 M\n",
    "small_eval_indices = eval_M\n",
    "small_test_indices = test_M\n",
    "\n",
    "# 打印小数据集划分结果\n",
    "print(f\"Small Train: {len(small_train_indices)} samples\")\n",
    "print(f\"Small Eval: {len(small_eval_indices)} samples\")\n",
    "print(f\"Small Test: {len(small_test_indices)} samples\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use dataloader traininig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to decide which dataset to use\n",
    "use_small_dataset = False  # 设置为 True 使用小数据集，False 使用大数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "batch_size = 10\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using full dataset for training and evaluation...\n"
     ]
    }
   ],
   "source": [
    "# 根据 flag 决定使用大数据集还是小数据集\n",
    "if use_small_dataset:\n",
    "    print(\"Using small dataset for training and evaluation...\")\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    eval_dataset = Subset(dataset, eval_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    train_loader =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "else:\n",
    "    print(\"Using full dataset for training and evaluation...\")\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    eval_dataset = Subset(dataset, eval_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = ModelCNN(output_fields=output_fields)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# 使用当前时间戳生成独特的日志目录名称\n",
    "# 超参数和自定义消息\n",
    "custom_message = \"straight_big\"\n",
    "\n",
    "# 动态生成日志目录\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_dir = f\"./logs/lr_{learning_rate}_msg_{custom_message}_{current_time}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved in: ./logs/lr_1e-05_msg_right_small_2024-11-20_00-54-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training:   0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.4785\n",
      "Eval Loss: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(eval_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Validating\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m eval_bar:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m eval_bar:\n\u001b[0;32m     40\u001b[0m             images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Work\\Anaconda\\envs\\udacity\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 初始化 TensorBoard\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(f\"TensorBoard logs will be saved in: {log_dir}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # tqdm 进度条 for 训练阶段\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\", leave=False) as train_bar:\n",
    "        for images, labels in train_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 更新 tqdm 信息\n",
    "            train_bar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # 计算 epoch 平均训练损失\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "\n",
    "    # tqdm 进度条 for 验证阶段\n",
    "    with tqdm(eval_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Validating\", leave=False) as eval_bar:\n",
    "        with torch.no_grad():\n",
    "            for images, labels in eval_bar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "                # 更新 tqdm 信息\n",
    "                eval_bar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # 计算 epoch 平均验证损失\n",
    "    avg_eval_loss = eval_loss / len(eval_loader)\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Eval Loss: {avg_eval_loss:.4f}\")\n",
    "\n",
    "    # 在同一张 TensorBoard 图上记录训练和验证损失\n",
    "    writer.add_scalars(\"Loss\", {\"Train\": avg_train_loss, \"Eval\": avg_eval_loss}, epoch)\n",
    "\n",
    "    # 可选：记录网络权重的直方图到 TensorBoard\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "\n",
    "\n",
    "# 关闭 TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# 定义模型保存路径\n",
    "save_dir = \"./models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 如果目录不存在，则创建\n",
    "\n",
    "# 保存模型\n",
    "model_save_path = os.path.join(save_dir, \"model_right_2_3outputs.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 测试阶段\n",
    "test_loss = 0\n",
    "model.eval()\n",
    "\n",
    "# tqdm 进度条 for 测试阶段\n",
    "with tqdm(test_loader, desc=\"Testing\", leave=False) as test_bar:\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "# 计算测试集平均损失\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models\\model_right_1st.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义模型保存路径\n",
    "save_dir = \"./models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 如果目录不存在，则创建\n",
    "\n",
    "# 保存模型\n",
    "model_save_path = os.path.join(save_dir, \"model_right_2_3outputs.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
